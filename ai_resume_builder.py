# -*- coding: utf-8 -*-
"""ai resume builder

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LPNdz--eRPAX6TPW7k59c6rzmBALGZPK
"""

!pip install nltk spacy pdfplumber docx2txt python-docx
!python -m spacy download en_core_web_sm

import os
import re
import spacy
import nltk
import pdfplumber
import docx2txt
from nltk.tokenize import sent_tokenize
from collections import Counter
from docx import Document
from docx.enum.style import WD_STYLE_TYPE

nlp = spacy.load('en_core_web_sm')

def extract_resume_text(file_path):
    text = ''
    if file_path.endswith('.pdf'):
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + '\n'
    elif file_path.endswith('.docx') or file_path.endswith('.doc'):
        text = docx2txt.process(file_path)
    elif file_path.endswith('.txt'):
        with open(file_path, 'r', encoding='utf-8') as file:
            text = file.read()
    else:
        raise ValueError('Unsupported file format!')
    return text

def extract_job_description(file_path):
    text = ''
    if file_path.endswith('.pdf'):
        with pdfplumber.open(file_path) as pdf:
            for page in pdf.pages:
                page_text = page.extract_text()
                if page_text:
                    text += page_text + '\n'
    elif file_path.endswith('.docx') or file_path.endswith('.doc'):
        text = docx2txt.process(file_path)
    elif file_path.endswith('.txt'):
        with open(file_path, 'r', encoding='utf-8') as file:
            text = file.read()
    else:
        raise ValueError('Unsupported job description file format!')
    return text

def extract_job_requirements(jd_text):
    doc = nlp(jd_text)
    sentences = [sent.text.strip() for sent in doc.sents]
    skills = []
    qualifications = []
    responsibilities = []
    for sent in sentences:
        sent_lower = sent.lower()
        if 'responsibilit' in sent_lower:
            responsibilities.extend(extract_items_from_text(sent))
        elif 'qualification' in sent_lower or 'requirement' in sent_lower:
            qualifications.extend(extract_items_from_text(sent))
        elif 'skill' in sent_lower:
            skills.extend(extract_items_from_text(sent))
    return skills, qualifications, responsibilities

def extract_items_from_text(text):
    # Split text into lines
    lines = text.split('\n')
    items = []
    for line in lines:
        line = line.strip()
        # Check for bullet points or numbered lists
        if re.match(r'^[-•\d\)$$]', line):
            # Remove bullet points or numbers
            item = re.sub(r'^[-•\d\.$$\(]+\s*', '', line)
            items.append(item)
        else:
            items.append(line)
    return items

def extract_candidate_profile(resume_text):
    doc = nlp(resume_text)
    # Extract noun chunks and verbs as potential skills and experiences
    skills = [chunk.text.lower() for chunk in doc.noun_chunks]
    verbs = [token.lemma_.lower() for token in doc if token.pos_ == 'VERB']
    # Extract named entities such as organizations, dates, etc.
    entities = [(ent.text, ent.label_) for ent in doc.ents]
    return skills, verbs, entities

def match_profile_to_job(candidate_skills, candidate_verbs, job_requirements):
    candidate_terms = set(candidate_skills + candidate_verbs)
    job_terms = set([req.lower() for req in job_requirements])
    matched_terms = candidate_terms.intersection(job_terms)
    return matched_terms

def generate_tailored_resume(resume_text, jd_text, matched_terms):
    # Reorganize resume to prioritize matched terms
    tailored_resume_sections = {}
    resume_lines = resume_text.split('\n')
    current_section = 'Other'
    for line in resume_lines:
        line = line.strip()
        # Detect section headers
        if re.match(r'^[A-Z][A-Za-z\s]+$', line) and len(line.split()) < 5:
            current_section = line
            tailored_resume_sections[current_section] = []
        else:
            if current_section not in tailored_resume_sections:
                tailored_resume_sections[current_section] = []
            tailored_resume_sections[current_section].append(line)

    # Rewriting sections to emphasize matched terms
    for section, contents in tailored_resume_sections.items():
        new_contents = []
        unmatched_contents = []
        for line in contents:
            line_lower = line.lower()
            if any(term in line_lower for term in matched_terms):
                # Emphasize the line by moving it up
                new_contents.append(line)
            else:
                unmatched_contents.append(line)
        # Combine matched and unmatched contents, with matched terms first
        tailored_resume_sections[section] = new_contents + unmatched_contents

    # Construct the tailored resume text
    tailored_resume_text = ''
    for section, contents in tailored_resume_sections.items():
        tailored_resume_text += section.upper() + '\n'
        tailored_resume_text += '\n'.join(contents) + '\n\n'
    return tailored_resume_text

def save_resume_to_word(resume_text, file_name):
    document = Document()
    paragraphs = resume_text.strip().split('\n\n')
    for para in paragraphs:
        lines = para.strip().split('\n')
        if len(lines) > 0:
            # Assuming the first line is the section header
            section_header = lines[0]
            content_lines = lines[1:]
            # Add section header
            document.add_heading(section_header, level=1)
            # Add content
            for line in content_lines:
                document.add_paragraph(line)
    document.save(file_name)

def main():
    # Paths to the candidate resume and job description
    resume_path = 'nandy.pdf'  # Replace with your resume file path
    jd_path = 'jd.txt'      # Replace with your job description file path

    # Extract texts
    resume_text = extract_resume_text(resume_path)
    jd_text = extract_job_description(jd_path)

    # Extract job requirements
    job_skills, job_qualifications, job_responsibilities = extract_job_requirements(jd_text)
    job_requirements = job_skills + job_qualifications + job_responsibilities

    # Extract candidate profile
    candidate_skills, candidate_verbs, candidate_entities = extract_candidate_profile(resume_text)

    # Match candidate profile with job requirements
    matched_terms = match_profile_to_job(candidate_skills, candidate_verbs, job_requirements)

    # Generate tailored resume
    tailored_resume_text = generate_tailored_resume(resume_text, jd_text, matched_terms)

    # Save the tailored resume as a Word document
    save_resume_to_word(tailored_resume_text, 'tailored_resume.docx')

    print("Tailored resume has been generated and saved to 'tailored_resume.docx'.")

def save_resume_to_word(resume_text, file_name):
    document = Document()
    paragraphs = resume_text.strip().split('\n\n')
    for para in paragraphs:
        lines = para.strip().split('\n')
        if len(lines) > 0:
            # Assuming the first line is the section header
            section_header = lines[0]
            content_lines = lines[1:]
            # Add section header
            document.add_heading(section_header, level=1)
            # Add content
            for line in content_lines:
                document.add_paragraph(line)
    document.save(file_name)

if __name__ == '__main__':
    main()
